{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc49196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\a.rashad\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d89d55a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (10.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca0c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3589c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image \n",
    "image_path = os.path.join('C:/Users/A.Rashad/Downloads/pic.JPG')\n",
    "img = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf75c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write image \n",
    "cv2.imwrite(os.path.join('C:/Users/A.Rashad/Downloads/pic_out.JPG'),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5795d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize image \n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f8ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a video \n",
    "video_path = os.path.join('C:/Users/A.Rashad/Downloads/vd.mp4')\n",
    "video = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2037d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize video\n",
    "ret = True \n",
    "while ret:\n",
    "    ret,frame = video.read()\n",
    "    \n",
    "    if ret:\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(40)\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f0aa2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read webcam \n",
    "webcam = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5eb907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize webcam \n",
    "\n",
    "while True:\n",
    "    ret,frame = webcam.read()\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(40) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e9e14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713, 1068, 3)\n"
     ]
    }
   ],
   "source": [
    "# resizing \n",
    "img = cv2.imread(os.path.join('C:/Users/A.Rashad/Downloads/pic.JPG'))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfca9449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534, 357, 3)\n"
     ]
    }
   ],
   "source": [
    "resized_img = cv2.resize(img, (357,534))\n",
    "print(resized_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4171cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('resized_img',resized_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60a393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713, 1068, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cropping \n",
    "img = cv2.imread(os.path.join('C:/Users/A.Rashad/Downloads/pic.JPG'))\n",
    "print(img.shape)\n",
    "\n",
    "cropped_img = img [320:640 , 420:840]  # H,W\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('cropped_img', cropped_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11c0833b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# color spaces \n",
    "\n",
    "img = cv2.imread(os.path.join('C:/Users/A.Rashad/Downloads/pic1.PNG'))\n",
    "\n",
    "img_rgb = cv2.cvtColor(img ,cv2.COLOR_BGR2RGB )\n",
    "img_gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('img_rgb', img_rgb)\n",
    "cv2.imshow('img_gray' , img_gray)\n",
    "cv2.imshow('img_hsv', img_hsv)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23679176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blurring \n",
    "\n",
    "img = cv2.imread(os.path.join('C:/Users/A.Rashad/Downloads/pic1.PNG'))\n",
    "\n",
    "k_size = 7\n",
    "img_blur = cv2.blur(img, (k_size, k_size))\n",
    "img_gaussian_blur = cv2.GaussianBlur(img, (k_size,k_size),3)\n",
    "img_median_blur = cv2.medianBlur(img, k_size)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_blur', img_blur)\n",
    "cv2.imshow('gaussian', img_gaussian_blur)\n",
    "cv2.imshow('median',img_median_blur)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b2edbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thresholding \n",
    "\n",
    "img = cv2.imread(os.path.join('C:/Users/A.Rashad/Downloads/pic1.PNG'))\n",
    "\n",
    "img_gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret , thresh = cv2.threshold(img_gray , 80 ,255 , cv2.THRESH_BINARY)\n",
    "\n",
    "thresh = cv2.blur(thresh, (10,10))\n",
    "ret , thresh = cv2.threshold(thresh,80,255,cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_gray', img_gray)\n",
    "cv2.imshow('thresh',thresh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12e63609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adaptive threshold \n",
    "\n",
    "img = cv2.imread(os.path.join('C:/Users/A.Rashad/Downloads/pic1.PNG'))\n",
    "\n",
    "img_gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(img_gray, 255 , cv2.ADAPTIVE_THRESH_GAUSSIAN_C  ,cv2.THRESH_BINARY, 21,30)\n",
    "\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('thresh', thresh)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a50ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf76fa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge detection \n",
    "\n",
    "img = cv2.imread(os.path.join('C:/Users/A.Rashad/Downloads/pic1.PNG'))\n",
    "\n",
    "img_edge = cv2.Canny(img , 100 ,200)\n",
    "\n",
    "img_edge_d = cv2.dilate(img_edge, np.ones((2,2), dtype=np.int8))\n",
    "img_edge_e = cv2.erode(img_edge_d, np.ones((2,2), dtype=np.int8))\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_edge', img_edge)\n",
    "cv2.imshow('img_edge_d', img_edge_d)\n",
    "cv2.imshow('img_edge_e',img_edge_e)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0aa80052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drawing \n",
    "\n",
    "img = cv2.imread(os.path.join('C:/Users/A.Rashad/Downloads/pic1.PNG'))\n",
    "\n",
    "\n",
    "#line\n",
    "cv2.line(img, (100,150),(300,450),(0,255,0),3)  # start of line , end of line , color , thinkness\n",
    "\n",
    "# rectangle\n",
    "cv2.rectangle(img,(100,250),(300,400),(0,0,255),-1)\n",
    "\n",
    "# circle\n",
    "cv2.circle(img,(200,100),100,(255,0,0),10)\n",
    "\n",
    "#text\n",
    "cv2.putText(img, 'hey ', (50 ,100), cv2.FONT_HERSHEY_SIMPLEX,4,(255,255,0),8)\n",
    "\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8deee209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d747f343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contours\n",
    "\n",
    "img = cv2.imread(os.path.join('C:/Users/A.Rashad/Downloads/pic1.PNG'))\n",
    "img_gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh=cv2.threshold(img_gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "contours , hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for cnt in contours:\n",
    "    if cv2.contourArea(cnt) > 300:\n",
    "       # cv2.drawContours(img, cnt,-1,(0,255,0),1)\n",
    "    \n",
    "       x1,y1,w,h = cv2.boundingRect(cnt)\n",
    "       cv2.rectangle(img,(x1,y1),(x1+w,y2+h),(0,255,0),3) \n",
    "\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('thresh', thresh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8377b9",
   "metadata": {},
   "source": [
    "# Color Detection ( using opencv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90dc94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "from PIL import Image \n",
    "#from util import get_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69edcf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Limits(color):\n",
    "    c = np.uint8([[color]])  # here insert the bgr values which you waqnt to convert to hsv \n",
    "    hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lowerLimit = hsvC[0][0][0] - 10,100,100\n",
    "    upperLimit = hsvC[0][0][0] - 10,255,255\n",
    "    \n",
    "    lowerLimit = np.array(lowerLimit, dtype = np.uint8)\n",
    "    upperLimit = np.array(upperLimit, dtype = np.uint8)\n",
    "    \n",
    "    return lowerLimit,upperLimit\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03f1110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yellow = [0,255,255] #yellow in bgr color space\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True :\n",
    "    ret , frame = cap.read()\n",
    "    \n",
    "    hsvimage = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lowerLimit,upperLimit = get_Limits(color = yellow)\n",
    "    \n",
    "    mask = cv2.inRange(hsvimage,lowerLimit,upperLimit)\n",
    "    \n",
    "    mask_ = Image.fromarray(mask)\n",
    "    \n",
    "    bbox = mask_.getbbox()\n",
    "    \n",
    "    if bbox is not None :\n",
    "        x1,y1,x2,y2 = bbox\n",
    "        frame = cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    if cv2.waitKey(40) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f34bd0",
   "metadata": {},
   "source": [
    "# Face Anonymizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f5bce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cae0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cb59674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img, face_detection):\n",
    "\n",
    "    H, W, _ = img.shape\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out = face_detection.process(img_rgb)\n",
    "\n",
    "    if out.detections is not None:\n",
    "        for detection in out.detections:\n",
    "            location_data = detection.location_data\n",
    "            bbox = location_data.relative_bounding_box\n",
    "\n",
    "            x1, y1, w, h = bbox.xmin, bbox.ymin, bbox.width, bbox.height\n",
    "\n",
    "            x1 = int(x1 * W)\n",
    "            y1 = int(y1 * H)\n",
    "            w = int(w * W)\n",
    "            h = int(h * H)\n",
    "\n",
    "            # print(x1, y1, w, h)\n",
    "\n",
    "            # blur faces\n",
    "            img[y1:y1 + h, x1:x1 + w, :] = cv2.blur(img[y1:y1 + h, x1:x1 + w, :], (30, 30))\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91e4730f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--mode MODE] [--filePath FILEPATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\A.Rashad\\AppData\\Roaming\\jupyter\\runtime\\kernel-c4f5c119-d636-4267-87ec-6ad93de884e3.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "args = argparse.ArgumentParser()\n",
    "\n",
    "args.add_argument(\"--mode\", default='webcam')\n",
    "args.add_argument(\"--filePath\", default=None)\n",
    "\n",
    "args = args.parse_args()\n",
    "\n",
    "\n",
    "output_dir = './output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# detect faces\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "\n",
    "    if args.mode in [\"image\"]:\n",
    "        # read image\n",
    "        img = cv2.imread(args.filePath)\n",
    "\n",
    "        img = process_img(img, face_detection)\n",
    "\n",
    "        # save image\n",
    "        cv2.imwrite(os.path.join(output_dir, 'output.png'), img)\n",
    "\n",
    "    elif args.mode in ['video']:\n",
    "\n",
    "        cap = cv2.VideoCapture(args.filePath)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        output_video = cv2.VideoWriter(os.path.join(output_dir, 'output.mp4'),\n",
    "                                       cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "                                       25,\n",
    "                                       (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "        while ret:\n",
    "\n",
    "            frame = process_img(frame, face_detection)\n",
    "\n",
    "            output_video.write(frame)\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "        cap.release()\n",
    "        output_video.release()\n",
    "\n",
    "    elif args.mode in ['webcam']:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        while ret:\n",
    "            frame = process_img(frame, face_detection)\n",
    "\n",
    "            cv2.imshow('frame', frame)\n",
    "            cv2.waitKey(25)\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c07d9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Check if running in a Jupyter Notebook\n",
    "try:\n",
    "    get_ipython\n",
    "    # Manually define arguments in the Jupyter notebook\n",
    "    args = lambda: None  # Create a blank object to simulate argparse\n",
    "    args.mode = \"webcam\"  # Set mode to \"webcam\" (or \"image\" or \"video\")\n",
    "    args.filePath = None  # You can set this to an image or video path if needed\n",
    "except NameError:\n",
    "    # Use argparse if not running in Jupyter\n",
    "    import argparse\n",
    "    args = argparse.ArgumentParser()\n",
    "    args.add_argument(\"--mode\", default='webcam')\n",
    "    args.add_argument(\"--filePath\", default=None)\n",
    "    args = args.parse_args()\n",
    "\n",
    "output_dir = './output'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# detect faces\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "def process_img(img, face_detection):\n",
    "    # Dummy function to process the image\n",
    "    results = face_detection.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            h, w, c = img.shape\n",
    "            bbox = int(bboxC.xmin * w), int(bboxC.ymin * h), \\\n",
    "                   int(bboxC.width * w), int(bboxC.height * h)\n",
    "            cv2.rectangle(img, bbox, (255, 0, 0), 2)\n",
    "    return img\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "\n",
    "    if args.mode == \"image\":\n",
    "        # Read and process image\n",
    "        img = cv2.imread(args.filePath)\n",
    "        img = process_img(img, face_detection)\n",
    "        cv2.imwrite(os.path.join(output_dir, 'output.png'), img)\n",
    "\n",
    "    elif args.mode == 'video':\n",
    "        cap = cv2.VideoCapture(args.filePath)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        output_video = cv2.VideoWriter(os.path.join(output_dir, 'output.mp4'),\n",
    "                                       cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "                                       25,\n",
    "                                       (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "        while ret:\n",
    "            frame = process_img(frame, face_detection)\n",
    "            output_video.write(frame)\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "        cap.release()\n",
    "        output_video.release()\n",
    "\n",
    "    elif args.mode == 'webcam':\n",
    "        cap = cv2.VideoCapture(0)  # Use default webcam (use 0 or 1 depending on your system)\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        while ret:\n",
    "            frame = process_img(frame, face_detection)\n",
    "            cv2.imshow('frame', frame)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c191229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
